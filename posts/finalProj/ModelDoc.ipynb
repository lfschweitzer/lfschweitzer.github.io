{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Final Project Results, Model Creation Document \n",
    "author: Sophie Seiple, Julia Joy, Lindsey Schweitzer\n",
    "date: '2024-01-01'\n",
    "description: \"Process of model creation.\"\n",
    "bibliography: refs.bib\n",
    "format: html\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_diabetes = pd.read_csv('conditions_diabetes.csv')\n",
    "conditions_pregnancy = pd.read_csv('conditions_pregnancy.csv')\n",
    "conditions_cancer = pd.read_csv('conditions_cancer.csv')\n",
    "conditions_heart = pd.read_csv('conditions_heart.csv')\n",
    "conditions_lungs = pd.read_csv('conditions_lungs.csv')\n",
    "\n",
    "observations = pd.read_csv('observations_pivot.csv')\n",
    "patients = pd.read_csv('patient_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note: All of our datasets are grouped by related diseases (for example diabetes and comorbitidies such as diabetic retinopathy), for the rest of the post, when we say \"diabetes\" or \"pregnancy complications,\" we are talking about diabetes and all present comorbidites, or a grouping of pregnancy complications such as pre/ante eclampsia and misscarriage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Modeling & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to prep our data for modelling we label encoded each of the qualitative variables (keeping track so we could decode them again later). We created a function in order to do this easily multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "# our data-prepping function for modeling\n",
    "def prep_data(df):\n",
    "    \n",
    "    # label encode all quantitative vars\n",
    "    df[\"race\"] = le.fit_transform(df[\"race\"]) \n",
    "    race_code = {code: race for code, race in enumerate(le.classes_)}\n",
    "\n",
    "    df[\"ethnicity\"] = le.fit_transform(df[\"ethnicity\"])\n",
    "    eth_code = {code: ethnicity for code, ethnicity in enumerate(le.classes_)}\n",
    "\n",
    "    df[\"gender\"] = le.fit_transform(df[\"gender\"])\n",
    "    gen_code = {code: gender for code, gender in enumerate(le.classes_)}\n",
    "\n",
    "    df[\"birthplace\"] = le.fit_transform(df[\"birthplace\"])\n",
    "    bp_code = {code: bp for code, bp in enumerate(le.classes_)}\n",
    "\n",
    "    df[\"curr_town\"] = le.fit_transform(df[\"curr_town\"]) \n",
    "    curr_code = {code: bp for code, bp in enumerate(le.classes_)}\n",
    "    \n",
    "    # split data into test and train\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train = train.drop(columns=['y'])\n",
    "    y_train = train['y']\n",
    "    \n",
    "    X_test = test.drop(columns=['y'])\n",
    "    y_test = test['y']\n",
    "    \n",
    "    # return split x, y, and all of the code tracking dicts\n",
    "    return X_train, y_train, X_test, y_test, race_code, eth_code, gen_code, bp_code, curr_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(300)\n",
    "X_train, y_train, X_test, y_test, race_code, eth_code, gen_code, bp_code, curr_code = prep_data(conditions_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finding optimal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we created a function we could reuse that identifies the best performing model on our data from the options random forest, SVC, logistic regression, and decision trees. The best model is what we use to predict the probability that each person has a certain disease (for our purposes, their risk score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model-finding function\n",
    "def train_model(X_train, y_train):\n",
    "    \n",
    "    #LogisticRegression\n",
    "    LR = LogisticRegression(max_iter=10000000000000000000)\n",
    "    LRScore = cross_val_score(LR, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    #DecisionTreeClassifier\n",
    "    param_grid = { 'max_depth': [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None ]}\n",
    "\n",
    "    tree = DecisionTreeClassifier()\n",
    "    grid_search = GridSearchCV(tree, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    DTCScore  = grid_search.best_score_\n",
    "    bestDTCDepth = grid_search.best_params_\n",
    "\n",
    "\n",
    "    # Random Forrest Classifier    \n",
    "    forrest = RandomForestClassifier(random_state=0)\n",
    "    grid_search = GridSearchCV(forrest, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    RFCScore  = grid_search.best_score_\n",
    "    bestRFCDepth = grid_search.best_params_\n",
    "\n",
    "    #SVC\n",
    "    SVM = SVC()\n",
    "\n",
    "    # use grid search to find best gamma for SVM\n",
    "    g = {'gamma': 10.0 ** np.arange(-5, 5) }\n",
    "    grid_search = GridSearchCV(SVM, g, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    SVMScore  = grid_search.best_score_   \n",
    "\n",
    "\n",
    "    print(\"best LR :\", LRScore)\n",
    "    print(\"best DTC:\", DTCScore)\n",
    "    print(\"best max depth: \", bestDTCDepth)\n",
    "    print(\"best RFC: \", RFCScore)\n",
    "    print(\"best max depth: \", bestRFCDepth)\n",
    "    print(\"best SVM: \", SVMScore)\n",
    "\n",
    "    # store the scores of each model\n",
    "    max_score = 0\n",
    "    max_model = \"\"\n",
    "    if LRScore > max_score:\n",
    "        max_score = LRScore\n",
    "        max_model = \"LR\"\n",
    "    if DTCScore > max_score:\n",
    "        max_score = DTCScore\n",
    "        max_model = \"DTC\"\n",
    "    if RFCScore > max_score:\n",
    "        max_score = RFCScore\n",
    "        max_model = \"RFC\"\n",
    "    if SVMScore > max_score:\n",
    "        max_score = SVMScore\n",
    "        max_model = \"SVM\"\n",
    "\n",
    "    print(\"best score overall is: \", max_score, \" with model: \", max_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best LR : 0.9050401672719269\n",
      "best DTC: 0.9178790213124979\n",
      "best max depth:  {'max_depth': 3}\n",
      "best RFC:  0.9153112505043837\n",
      "best max depth:  {'max_depth': 5}\n",
      "best SVM:  0.9016066908770772\n",
      "best score overall is:  0.9178790213124979  with model:  DTC\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# run model finding function on our diabetes data\n",
    "np.random.seed(500)\n",
    "train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of our function should that the decision tree classifier is the best model possible, with an accuracy of 91.78%. Our accuracies tend generally lower considering the limited information we allowed the model to have, as we really wanted to see what the model would do when it predicted on identity factors such as race, ethnicity, and birthplace, and not how it would predict given information on the specific procedures and allergies a patient had."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Risk Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict probabilities for all our entries using the best model we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=3)\n",
    "dtc.fit(X_train, y_train)\n",
    "pred_prob = dtc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease we created a risk finding function that can be used across factors and disease probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_risk(code, col, probs):\n",
    "    # finds the corresponding subset of our probability data\n",
    "    indices = (X_test[col] == code)\n",
    "    prob_subset = probs[indices]\n",
    "    # finds the average of this subset\n",
    "    av_prob = np.mean(prob_subset[:, 1]) \n",
    "    return av_prob   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compare Across Race, Gender, Ethnicity\n",
    "Next, we find the average risk score for different demographic characteristics: Race, Gender, and Ethnicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.479592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.340659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>0.312536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0.256158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       race      risk\n",
       "0     asian  0.479592\n",
       "2  hispanic  0.340659\n",
       "3     white  0.312536\n",
       "1     black  0.256158"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetesRaceRisk = []\n",
    "\n",
    "# find risk for each race (after finding on their code from the label encoder)\n",
    "for code, race in race_code.items():\n",
    "    avRisk = find_risk(code, 'race', pred_prob)\n",
    "    newRow = {'race': race, 'risk': avRisk}\n",
    "    diabetesRaceRisk.append(newRow)\n",
    "\n",
    "# print summary table\n",
    "diabetesRaceRisk = pd.DataFrame(diabetesRaceRisk)\n",
    "diabetesRaceRisk = diabetesRaceRisk.sort_values(by='risk', ascending=False)\n",
    "diabetesRaceRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model tells us that the most susceptible group to diabetes is Asian, then Hispanic and White, with Black being the least susceptible. These results were interesting in that they do indeed indicate that there may be a difference according to race, and made us think of how we could explore demographic information about Massachussetts (where our data is \"from\"), to understand whether these trends are reflective of larger trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.375356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.263908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender      risk\n",
       "0      F  0.375356\n",
       "1      M  0.263908"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetesGenderRisk = []\n",
    "\n",
    "for code, gender in gen_code.items():\n",
    "    avRisk = find_risk(code, 'gender', pred_prob)\n",
    "    newRow = {'gender': gender, 'risk': avRisk}\n",
    "    diabetesGenderRisk.append(newRow)\n",
    "\n",
    "diabetesGenderRisk = pd.DataFrame(diabetesGenderRisk)\n",
    "diabetesGenderRisk = diabetesGenderRisk.sort_values(by='risk', ascending=False)\n",
    "diabetesGenderRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model tells us that women are slightly more likely to experience diabetes (or comorbidities) than men, which is in line with medical research we've seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eth</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asian_indian</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>polish</td>\n",
       "      <td>0.558405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>german</td>\n",
       "      <td>0.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>0.369491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>scottish</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>puerto_rican</td>\n",
       "      <td>0.329670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dominican</td>\n",
       "      <td>0.328571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>african</td>\n",
       "      <td>0.318681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>italian</td>\n",
       "      <td>0.314127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>central_american</td>\n",
       "      <td>0.306122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>french</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>french_canadian</td>\n",
       "      <td>0.261905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.244898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>swedish</td>\n",
       "      <td>0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>russian</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>irish</td>\n",
       "      <td>0.182902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>west_indian</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 eth      risk\n",
       "2       asian_indian  0.714286\n",
       "13            polish  0.558405\n",
       "9             german  0.492674\n",
       "12           mexican  0.428571\n",
       "1           american  0.428571\n",
       "14        portuguese  0.397959\n",
       "6            english  0.369491\n",
       "17          scottish  0.333333\n",
       "15      puerto_rican  0.329670\n",
       "5          dominican  0.328571\n",
       "0            african  0.318681\n",
       "11           italian  0.314127\n",
       "3   central_american  0.306122\n",
       "7             french  0.285714\n",
       "8    french_canadian  0.261905\n",
       "4            chinese  0.244898\n",
       "18           swedish  0.205128\n",
       "16           russian  0.200000\n",
       "10             irish  0.182902\n",
       "19       west_indian  0.000000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_risk_eth = []\n",
    "\n",
    "for code, name in eth_code.items():\n",
    "    av = find_risk(code, 'ethnicity', pred_prob)\n",
    "    new_row = {'eth': name, 'risk': av}\n",
    "    av_risk_eth.append(new_row)\n",
    "\n",
    "av_risk_eth_df = pd.DataFrame(av_risk_eth)\n",
    "av_risk_eth_df = av_risk_eth_df.sort_values(by='risk', ascending=False)\n",
    "av_risk_eth_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table gives us lots of information about risk by ethnicity, most interestingly perhaps, it agrees with our race finding that Asian people are more likely to experience diabetes, in that our most at risk ethnicity was Asian Indian. However, Chinese and West Indian, the two other Asian ethnicities in the datasest are at the bottom of the risk hierarchy, which made us consider that the risk of Asian Indian people specifically, and alone, was what was driving our race findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Compare Across Wealthier & Poorer Towns of Residence/Birthplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare outcomes across towns of varying socioeconomic status, we compiled a list of the richest and poorest towns present in our dataset (using Census data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# richest towns in Mass\n",
    "richTowns = [\"Dover\", \"Weston\", \"Wellesley\", \"Lexington\", \"Sherborn\", \"Cohasset\", \"Lincoln\", \"Carlisle\", \"Hingham\", \"Winchester\", \n",
    "                \"Medfield\", \"Concord\", \"Needham\", \"Sudbury\", \"Hopkinton\", \"Boxford\", \"Brookline\", \"Andover\",  \n",
    "                  \"Southborough\", \"Belmont\", \"Acton\", \"Marblehead\", \"Newton\", \"Nantucket\", \"Duxbury\", \"Boxborough\", \"Westwood\",\"Natick\", \n",
    "                  \"Longmeadow\", \"Marion\", \"Groton\", \"Newbury\", \"North Andover\", \"Sharon\", \"Arlington\", \"Norwell\", \"Reading\", \n",
    "                  \"Lynnfield\", \"Marshfield\", \"Holliston\", \"Medway\", \"Canton\", \"Milton\", \"Ipswich\", \"Littleton\", \"Westford\", \"North Reading\", \"Chelmsford\", \"Dedham\",\n",
    "                  \"Walpole\", \"Mansfield\", \"Shrewsbury\", \"Norwood\", \"Hanover\", \"Stow\", \"Newburyport\", \"Chatham\", \"Orleans\", \"Harwich\",\n",
    "                  \"Swampscott\",\"Fairhaven\", \"Salem\"]\n",
    "\n",
    "# poorest towns in Mass\n",
    "poorTowns = [\"Springfield\", \"Lawrence\", \"Holyoke\", \"Amherst\", \"New Bedford\", \"Chelsea\", \"Fall River\", \"Athol\", \"Orange\", \"Lynn\", \"Fitchburg\", \"Gardner\", \"Brockton\", \"Malden\", \"Worcester\", \"Chicopee\", \"North Adams\", \"Everett\",\n",
    "    \"Ware\", \"Dudley\", \"Greenfield Town\", \"Weymouth Town\", \"Montague\", \"Revere\", \"Taunton\", \"Adams\", \"Huntington\", \"Charlemont\", \"Leominster\", \"Florida\", \"Colrain\", \"Hardwick\",\n",
    "    \"Palmer Town\", \"Peabody\", \"Somerville\", \"Lowell\", \"Westfield\", \"Billerica\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a df with all the information for the rich and poor towns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_town_info_row(town, bp_code_swapped, townCounts_df, code_name):\n",
    "    code = bp_code_swapped[town]\n",
    "    \n",
    "    if not townCounts_df[townCounts_df[code_name] == code].empty:\n",
    "        count = townCounts_df[townCounts_df[code_name] == code]['count'].values[0]\n",
    "    else:\n",
    "        count = 0\n",
    "    \n",
    "    new_row = {code_name: town, 'code': code, 'count': count}\n",
    "    \n",
    "    new_row_df = pd.DataFrame([new_row])\n",
    "    \n",
    "    return new_row_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_town_info_all(counts, code_name):\n",
    "    \n",
    "    townCounts_df = pd.merge(X_test, counts, on=code_name)\n",
    "    town_info_rich = pd.DataFrame(columns=[code_name, 'code', 'count'])\n",
    "    town_info_poor = pd.DataFrame(columns=[code_name, 'code', 'count'])\n",
    "\n",
    "    bp_code_swapped = {value: key for key, value in bp_code.items()}\n",
    "\n",
    "    for town in richTowns:\n",
    "        \n",
    "        new_row_df = find_town_info_row(town, bp_code_swapped, townCounts_df, code_name)\n",
    "        town_info_rich = pd.concat([town_info_rich, new_row_df], ignore_index=True)\n",
    "\n",
    "    for town in poorTowns:\n",
    "        \n",
    "        new_row_df = find_town_info_row(town, bp_code_swapped, townCounts_df, code_name)\n",
    "        town_info_poor= pd.concat([town_info_poor, new_row_df], ignore_index=True)\n",
    "        \n",
    "    return town_info_rich, town_info_poor\n",
    "\n",
    "birthplace_counts = X_test.groupby('birthplace').size().reset_index(name='count')\n",
    "\n",
    "town_info_rich, town_info_poor = find_town_info_all(birthplace_counts, 'birthplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed with the following code to get the list of towns that sum up to 65 people from the richest towns, and 65 people from the poorest towns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_towns_by_sum_pop(town_info, code_name):\n",
    "    \n",
    "    townsUsed = set()\n",
    "    peopleCount = 0\n",
    "\n",
    "    for index, row in town_info.iterrows():\n",
    "        \n",
    "        if peopleCount > 65:\n",
    "            break\n",
    "        \n",
    "        name = row[code_name]\n",
    "        count = row['count']\n",
    "        townsUsed.add(name)\n",
    "        peopleCount += count\n",
    "    \n",
    "    return townsUsed, peopleCount\n",
    "\n",
    "richTownsUsed, richPeopleCount = get_towns_by_sum_pop(town_info_rich, 'birthplace')\n",
    "poorTownsUsed, poorPeopleCount = get_towns_by_sum_pop(town_info_poor, 'birthplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birthplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_av_prob_bp(townsUsed, code_name, bp_code):\n",
    "    \n",
    "    town_codes = []\n",
    "    bp_code_swapped = {value: key for key, value in bp_code.items()}\n",
    "\n",
    "\n",
    "    for town_full in townsUsed:\n",
    "        town_codes.append(bp_code_swapped[town_full])\n",
    "        \n",
    "    indices = X_test[code_name].isin(town_codes)\n",
    "    prob_subset = pred_prob[indices]\n",
    "    av_prob = np.mean(prob_subset[:, 1]) \n",
    "\n",
    "    return av_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_rich_prob:  0.33305156382079454 av_poor_prob:  0.31947027331642713\n"
     ]
    }
   ],
   "source": [
    "av_rich_prob = get_av_prob_bp(richTownsUsed, 'birthplace', bp_code)\n",
    "av_poor_prob = get_av_prob_bp(poorTownsUsed, 'birthplace', bp_code)\n",
    "\n",
    "print(\"av_rich_prob: \", av_rich_prob, \"av_poor_prob: \", av_poor_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that there is not much difference in the average risk of diabetes when comparing poor and rich birthplace towns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Town of Residence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with the information for rich and poor towns. Then get the list of towns that sum up to 65 people from the richest towns, and 65 people from the poorest towns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_counts = X_test.groupby('curr_town').size().reset_index(name='count')\n",
    "town_info_rich, town_info_poor = find_town_info_all(curr_counts, 'curr_town')\n",
    "\n",
    "richTownsUsed, richPeopleCount = get_towns_by_sum_pop(town_info_rich, 'curr_town')\n",
    "poorTownsUsed, poorPeopleCount = get_towns_by_sum_pop(town_info_poor, 'curr_town')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_rich_prob:  0.25274725274725274 av_poor_prob:  0.2827087442472057\n"
     ]
    }
   ],
   "source": [
    "av_rich_prob = get_av_prob_bp(richTownsUsed, 'curr_town', bp_code)\n",
    "av_poor_prob = get_av_prob_bp(poorTownsUsed, 'curr_town', bp_code)\n",
    "#HERE\n",
    "\n",
    "print(\"av_rich_prob: \", av_rich_prob, \"av_poor_prob: \", av_poor_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this comparison, we find that people currently residing in rich towns have slightly lower rates of diabetes than those residing in poorer towns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregnancy Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeated the same exact process as above for each of our condition subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(567)\n",
    "X_train, y_train, X_test, y_test, race_code, eth_code, gen_code, bp_code, curr_code = prep_data(conditions_pregnancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best LR : 0.9538094714060378\n",
      "best DTC: 0.9632185172957705\n",
      "best max depth:  {'max_depth': 1}\n",
      "best RFC:  0.9632185172957705\n",
      "best max depth:  {'max_depth': 1}\n",
      "best SVM:  0.9632185172957705\n",
      "best score overall is:  0.9632185172957705  with model:  DTC\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(567)\n",
    "train_model(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Average Risk scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict probabilities for all our entries using the best model we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(max_depth=1)\n",
    "DTC.fit(X_train, y_train)\n",
    "pred_prob = DTC.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0.051395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.038217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.037262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>0.034260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       race      risk\n",
       "1     black  0.051395\n",
       "2  hispanic  0.038217\n",
       "0     asian  0.037262\n",
       "3     white  0.034260"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pregRaceRisk = []\n",
    "\n",
    "for code, race in race_code.items():\n",
    "    avRisk = find_risk(code, 'race', pred_prob)\n",
    "    newRow = {'race': race, 'risk': avRisk}\n",
    "    pregRaceRisk.append(newRow)\n",
    "\n",
    "pregRaceRisk = pd.DataFrame(pregRaceRisk)\n",
    "pregRaceRisk = pregRaceRisk.sort_values(by='risk', ascending=False)\n",
    "pregRaceRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that being black gives a patient a little less than double the risk of pregnancy issues than being white. Hispanics have the second highest rate of pregnancy complications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.074523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender      risk\n",
       "0      F  0.074523\n",
       "1      M  0.000000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pregGenderRisk = []\n",
    "\n",
    "for code, gender in gen_code.items():\n",
    "    avRisk = find_risk(code, 'gender', pred_prob)\n",
    "    newRow = {'gender': gender, 'risk': avRisk}\n",
    "    pregGenderRisk.append(newRow)\n",
    "\n",
    "pregGenderRisk = pd.DataFrame(pregGenderRisk)\n",
    "pregGenderRisk = pregGenderRisk.sort_values(by='risk', ascending=False)\n",
    "pregGenderRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result may seem a bit redundant or silly, it makes sense as generally people identified as male do not get pregnant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_risk_eth = []\n",
    "\n",
    "for code, name in eth_code.items():\n",
    "    av = find_risk(code, 'ethnicity', pred_prob)\n",
    "    new_row = {'eth': name, 'risk': av}\n",
    "    av_risk_eth.append(new_row)\n",
    "\n",
    "av_risk_eth_df = pd.DataFrame(av_risk_eth)\n",
    "av_risk_eth_df = av_risk_eth_df.sort_values(by='risk', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eth</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dominican</td>\n",
       "      <td>0.074523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>scottish</td>\n",
       "      <td>0.074523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american</td>\n",
       "      <td>0.054199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>central_american</td>\n",
       "      <td>0.053231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>west_indian</td>\n",
       "      <td>0.049682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>french_canadian</td>\n",
       "      <td>0.049682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.049682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.047908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.042585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>french</td>\n",
       "      <td>0.039746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>italian</td>\n",
       "      <td>0.038269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>0.036060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>african</td>\n",
       "      <td>0.034395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asian_indian</td>\n",
       "      <td>0.031939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>puerto_rican</td>\n",
       "      <td>0.031529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>swedish</td>\n",
       "      <td>0.029809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>irish</td>\n",
       "      <td>0.025262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>polish</td>\n",
       "      <td>0.024841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>german</td>\n",
       "      <td>0.023289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>russian</td>\n",
       "      <td>0.014905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 eth      risk\n",
       "5          dominican  0.074523\n",
       "17          scottish  0.074523\n",
       "1           american  0.054199\n",
       "3   central_american  0.053231\n",
       "19       west_indian  0.049682\n",
       "8    french_canadian  0.049682\n",
       "12           mexican  0.049682\n",
       "14        portuguese  0.047908\n",
       "4            chinese  0.042585\n",
       "7             french  0.039746\n",
       "11           italian  0.038269\n",
       "6            english  0.036060\n",
       "0            african  0.034395\n",
       "2       asian_indian  0.031939\n",
       "15      puerto_rican  0.031529\n",
       "18           swedish  0.029809\n",
       "10             irish  0.025262\n",
       "13            polish  0.024841\n",
       "9             german  0.023289\n",
       "16           russian  0.014905"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_risk_eth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that our finding that Black patients are more likely to experience pregnancy-related  complications is driven largely by Dominican patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birthplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthplace_counts = X_test.groupby('birthplace').size().reset_index(name='count')\n",
    "town_info_rich, town_info_poor = find_town_info_all(birthplace_counts, 'birthplace')\n",
    "richTownsUsed, richPeopleCount = get_towns_by_sum_pop(town_info_rich, 'birthplace')\n",
    "poorTownsUsed, poorPeopleCount = get_towns_by_sum_pop(town_info_poor, 'birthplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_rich_prob:  0.038981469137448335 av_poor_prob:  0.03668844154112784\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(234)\n",
    "\n",
    "av_rich_prob = get_av_prob_bp(richTownsUsed, 'birthplace', bp_code)\n",
    "av_poor_prob = get_av_prob_bp(poorTownsUsed, 'birthplace', bp_code)\n",
    "\n",
    "print(\"av_rich_prob: \", av_rich_prob, \"av_poor_prob: \", av_poor_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Town of Residence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_counts = X_test.groupby('curr_town').size().reset_index(name='count')\n",
    "town_info_rich, town_info_poor = find_town_info_all(curr_counts, 'curr_town')\n",
    "richTownsUsed, richPeopleCount = get_towns_by_sum_pop(town_info_rich, 'curr_town')\n",
    "poorTownsUsed, poorPeopleCount = get_towns_by_sum_pop(town_info_poor, 'curr_town')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_rich_prob:  0.04586055192640981 av_poor_prob:  0.03630627027507444\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(234)\n",
    "av_rich_prob = get_av_prob_bp(richTownsUsed, 'curr_town', bp_code)\n",
    "av_poor_prob = get_av_prob_bp(poorTownsUsed, 'curr_town', bp_code)\n",
    "\n",
    "print(\"av_rich_prob: \", av_rich_prob, \"av_poor_prob: \", av_poor_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finding was somewhat surprising to us, in that wealthier towns were found to have higher risks of pregnancy complications. We discuss the potential implications of this result in our results section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best LR : 0.9486775980338212\n",
      "best DTC: 0.9546641722607386\n",
      "best max depth:  {'max_depth': 1}\n",
      "best RFC:  0.9546641722607386\n",
      "best max depth:  {'max_depth': 1}\n",
      "best SVM:  0.9546641722607386\n",
      "best score overall is:  0.9546641722607386  with model:  DTC\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "X_train, y_train, X_test, y_test, race_code, eth_code, gen_code, bp_code, curr_code = prep_data(conditions_cancer)\n",
    "\n",
    "#getting rid of few NaN values\n",
    "X_train.fillna(0.0, inplace=True)\n",
    "#train the model\n",
    "np.random.seed(500)\n",
    "train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we find that the model with the best score is DTC, The Decision Tree Classifier, with about 98% accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(max_depth=1)\n",
    "DTC.fit(X_train, y_train)\n",
    "pred_prob = DTC.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>0.051942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.051650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0.046859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.034009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       race      risk\n",
       "3     white  0.051942\n",
       "2  hispanic  0.051650\n",
       "1     black  0.046859\n",
       "0     asian  0.034009"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancerRaceRisk = []\n",
    "\n",
    "for code, race in race_code.items():\n",
    "    avRisk = find_risk(code, 'race', pred_prob)\n",
    "    newRow = {'race': race, 'risk': avRisk}\n",
    "    cancerRaceRisk.append(newRow)\n",
    "\n",
    "cancerRaceRisk = pd.DataFrame(cancerRaceRisk)\n",
    "cancerRaceRisk = cancerRaceRisk.sort_values(by='risk', ascending=False)\n",
    "cancerRaceRisk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find across the board cancer rates are somewhat even, but that at the extremes white patients have almost a 52% risk of being classified with cancer,and Asian patients have around a 34% risk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.053825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.047147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender      risk\n",
       "1      M  0.053825\n",
       "0      F  0.047147"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancerGenderRisk = []\n",
    "\n",
    "for code, gender in gen_code.items():\n",
    "    avRisk = find_risk(code, 'gender', pred_prob)\n",
    "    newRow = {'gender': gender, 'risk': avRisk}\n",
    "    cancerGenderRisk.append(newRow)\n",
    "\n",
    "cancerGenderRisk = pd.DataFrame(cancerGenderRisk)\n",
    "cancerGenderRisk = cancerGenderRisk.sort_values(by='risk', ascending=False)\n",
    "cancerGenderRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Women are slightly less likely to have cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eth</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>german</td>\n",
       "      <td>0.105675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>puerto_rican</td>\n",
       "      <td>0.067085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>african</td>\n",
       "      <td>0.067085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.062675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>italian</td>\n",
       "      <td>0.059576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>0.057127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>polish</td>\n",
       "      <td>0.049934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>irish</td>\n",
       "      <td>0.049557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.048342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>swedish</td>\n",
       "      <td>0.045475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dominican</td>\n",
       "      <td>0.045475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american</td>\n",
       "      <td>0.041827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>central_american</td>\n",
       "      <td>0.034009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>french</td>\n",
       "      <td>0.032097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asian_indian</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>french_canadian</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>west_indian</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>russian</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>scottish</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 eth      risk\n",
       "9             german  0.105675\n",
       "15      puerto_rican  0.067085\n",
       "0            african  0.067085\n",
       "4            chinese  0.062675\n",
       "11           italian  0.059576\n",
       "6            english  0.057127\n",
       "13            polish  0.049934\n",
       "10             irish  0.049557\n",
       "14        portuguese  0.048342\n",
       "18           swedish  0.045475\n",
       "5          dominican  0.045475\n",
       "1           american  0.041827\n",
       "3   central_american  0.034009\n",
       "7             french  0.032097\n",
       "2       asian_indian  0.005342\n",
       "8    french_canadian  0.005342\n",
       "12           mexican  0.005342\n",
       "19       west_indian  0.005342\n",
       "16           russian  0.005342\n",
       "17          scottish  0.005342"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancerEthRisk = []\n",
    "\n",
    "for code, name in eth_code.items():\n",
    "    av = find_risk(code, 'ethnicity', pred_prob)\n",
    "    new_row = {'eth': name, 'risk': av}\n",
    "    cancerEthRisk.append(new_row)\n",
    "\n",
    "cancerEthRisk = pd.DataFrame(cancerEthRisk)\n",
    "cancerEthRisk = cancerEthRisk.sort_values(by='risk', ascending=False)\n",
    "\n",
    "cancerEthRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results for ethnicity largely match the results we found distinguishing by race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birthplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_rich_prob:  0.06399830132085002 av_poor_prob:  0.04238804096017698\n"
     ]
    }
   ],
   "source": [
    "av_rich_prob = get_av_prob_bp(richTownsUsed, 'birthplace', bp_code)\n",
    "av_poor_prob = get_av_prob_bp(poorTownsUsed, 'birthplace', bp_code)\n",
    "\n",
    "print(\"av_rich_prob: \", av_rich_prob, \"av_poor_prob: \", av_poor_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Town of Residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_rich_prob:  0.03621368085712754 av_poor_prob:  0.05164958111475114\n"
     ]
    }
   ],
   "source": [
    "av_rich_prob = get_av_prob_bp(richTownsUsed, 'curr_town', bp_code)\n",
    "av_poor_prob = get_av_prob_bp(poorTownsUsed, 'curr_town', bp_code)\n",
    "\n",
    "print(\"av_rich_prob: \", av_rich_prob, \"av_poor_prob: \", av_poor_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that for birthplace, people in rich towns are more likely to get diagnosed with cancer as opposed to people from poorer towns. For current town of residence, the opposite is true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophie/anaconda3/envs/ml-0451/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sophie/anaconda3/envs/ml-0451/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best LR : 0.87766773045743\n",
      "best DTC: 0.8973478595796193\n",
      "best max depth:  {'max_depth': 1}\n",
      "best RFC:  0.8999156303877335\n",
      "best max depth:  {'max_depth': None}\n",
      "best SVM:  0.8973478595796193\n",
      "best score overall is:  0.8999156303877335  with model:  RFC\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(210)\n",
    "X_train, y_train, X_test, y_test, race_code, eth_code, gen_code, bp_code, curr_code = prep_data(conditions_heart)\n",
    "\n",
    "#getting rid of few NaN values\n",
    "X_train.fillna(0.0, inplace=True)\n",
    "#train the model\n",
    "np.random.seed(20)\n",
    "train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Average Risk scores\n",
    "We found that the best model to predict probabilities for all our entries in this case would be RFC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(random_state=0, max_depth=1)\n",
    "RFC.fit(X_train, y_train)\n",
    "\n",
    "pred_prob = RFC.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compare Across Race, Gender, Ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.510746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>0.502101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0.491353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.491280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       race      risk\n",
       "0     asian  0.510746\n",
       "3     white  0.502101\n",
       "1     black  0.491353\n",
       "2  hispanic  0.491280"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartRaceRisk = []\n",
    "\n",
    "for code, race in race_code.items():\n",
    "    avRisk = find_risk(code, 'race', pred_prob)\n",
    "    newRow = {'race': race, 'risk': avRisk}\n",
    "    heartRaceRisk.append(newRow)\n",
    "\n",
    "heartRaceRisk = pd.DataFrame(heartRaceRisk)\n",
    "heartRaceRisk = heartRaceRisk.sort_values(by='risk', ascending=False)\n",
    "heartRaceRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the demographic with the highest likelihood of having heart problems is Asian, but overall the results are fairly even."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.508013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.492275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender      risk\n",
       "0      F  0.508013\n",
       "1      M  0.492275"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartGenderRisk = []\n",
    "\n",
    "for code, gender in gen_code.items():\n",
    "    avRisk = find_risk(code, 'gender', pred_prob)\n",
    "    newRow = {'gender': gender, 'risk': avRisk}\n",
    "    heartGenderRisk.append(newRow)\n",
    "\n",
    "heartGenderRisk = pd.DataFrame(heartGenderRisk)\n",
    "heartGenderRisk = heartGenderRisk.sort_values(by='risk', ascending=False)\n",
    "heartGenderRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our results, women and men are equally likely to have heart conditions, which disagrees with real medical trends that show men are much more likely to have these conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eth</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asian_indian</td>\n",
       "      <td>0.556735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>scottish</td>\n",
       "      <td>0.556144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>polish</td>\n",
       "      <td>0.553649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.534791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.519123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american</td>\n",
       "      <td>0.516831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>german</td>\n",
       "      <td>0.516270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>russian</td>\n",
       "      <td>0.511412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>swedish</td>\n",
       "      <td>0.508385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>0.500485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>african</td>\n",
       "      <td>0.500460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>french</td>\n",
       "      <td>0.498784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>french_canadian</td>\n",
       "      <td>0.494611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>italian</td>\n",
       "      <td>0.490876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>west_indian</td>\n",
       "      <td>0.489579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>irish</td>\n",
       "      <td>0.489033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>central_american</td>\n",
       "      <td>0.487097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>puerto_rican</td>\n",
       "      <td>0.482365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dominican</td>\n",
       "      <td>0.480579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.464757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 eth      risk\n",
       "2       asian_indian  0.556735\n",
       "17          scottish  0.556144\n",
       "13            polish  0.553649\n",
       "12           mexican  0.534791\n",
       "14        portuguese  0.519123\n",
       "1           american  0.516831\n",
       "9             german  0.516270\n",
       "16           russian  0.511412\n",
       "18           swedish  0.508385\n",
       "6            english  0.500485\n",
       "0            african  0.500460\n",
       "7             french  0.498784\n",
       "8    french_canadian  0.494611\n",
       "11           italian  0.490876\n",
       "19       west_indian  0.489579\n",
       "10             irish  0.489033\n",
       "3   central_american  0.487097\n",
       "15      puerto_rican  0.482365\n",
       "5          dominican  0.480579\n",
       "4            chinese  0.464757"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartEthRisk = []\n",
    "\n",
    "for code, name in eth_code.items():\n",
    "    av = find_risk(code, 'ethnicity', pred_prob)\n",
    "    new_row = {'eth': name, 'risk': av}\n",
    "    heartEthRisk.append(new_row)\n",
    "\n",
    "heartEthRisk = pd.DataFrame(heartEthRisk)\n",
    "heartEthRisk = heartEthRisk.sort_values(by='risk', ascending=False)\n",
    "\n",
    "heartEthRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, here we see very little variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birthplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_rich_prob:  0.10892307692307693 av_poor_prob:  0.1103076923076923\n"
     ]
    }
   ],
   "source": [
    "av_rich_prob = get_av_prob_bp(richTownsUsed, 'birthplace', bp_code)\n",
    "av_poor_prob = get_av_prob_bp(poorTownsUsed, 'birthplace', bp_code)\n",
    "\n",
    "print(\"av_rich_prob: \", av_rich_prob, \"av_poor_prob: \", av_poor_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Town of Residence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_rich_prob:  0.08661538461538462 av_poor_prob:  0.09256410256410255\n"
     ]
    }
   ],
   "source": [
    "av_rich_prob = get_av_prob_bp(richTownsUsed, 'curr_town', bp_code)\n",
    "av_poor_prob = get_av_prob_bp(poorTownsUsed, 'curr_town', bp_code)\n",
    "\n",
    "print(\"av_rich_prob: \", av_rich_prob, \"av_poor_prob: \", av_poor_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems as if there are not significant differences between the risk of heart diseases between wealthier and less-wealthy birthplace towns or current towns of residence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lungs Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best LR : 0.5705770147830234\n",
      "best DTC: 0.6107626279300099\n",
      "best max depth:  {'max_depth': 5}\n",
      "best RFC:  0.6210850665786289\n",
      "best max depth:  {'max_depth': 4}\n",
      "best SVM:  0.5971387696709585\n",
      "best score overall is:  0.6210850665786289  with model:  RFC\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(400)\n",
    "X_train, y_train, X_test, y_test, race_code, eth_code, gen_code, bp_code, curr_code = prep_data(conditions_lungs)\n",
    "\n",
    "#getting rid of few NaN values\n",
    "X_train.fillna(0.0, inplace=True)\n",
    "#train the model\n",
    "train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Average Risk scores\n",
    "We found that the best model to predict probabilities for all our entries iin this case would be RFC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(random_state=0, max_depth=4)\n",
    "RFC.fit(X_train, y_train)\n",
    "\n",
    "pred_prob = RFC.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compare Across Race, Gender, Ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.514338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0.509092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>0.507817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.492106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       race      risk\n",
       "0     asian  0.514338\n",
       "1     black  0.509092\n",
       "3     white  0.507817\n",
       "2  hispanic  0.492106"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lungsRaceRisk = []\n",
    "\n",
    "for code, race in race_code.items():\n",
    "    avRisk = find_risk(code, 'race', pred_prob)\n",
    "    newRow = {'race': race, 'risk': avRisk}\n",
    "    lungsRaceRisk.append(newRow)\n",
    "\n",
    "lungsRaceRisk = pd.DataFrame(lungsRaceRisk)\n",
    "lungsRaceRisk = lungsRaceRisk.sort_values(by='risk', ascending=False)\n",
    "lungsRaceRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find very little variation for risk rates for lung issues for race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.519215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.493550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender      risk\n",
       "0      F  0.519215\n",
       "1      M  0.493550"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lungsGenderRisk = []\n",
    "\n",
    "for code, gender in gen_code.items():\n",
    "    avRisk = find_risk(code, 'gender', pred_prob)\n",
    "    newRow = {'gender': gender, 'risk': avRisk}\n",
    "    lungsGenderRisk.append(newRow)\n",
    "\n",
    "lungsGenderRisk = pd.DataFrame(lungsGenderRisk)\n",
    "lungsGenderRisk = lungsGenderRisk.sort_values(by='risk', ascending=False)\n",
    "lungsGenderRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, there are pretty even rates for gender and risk of having lung complications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eth</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>polish</td>\n",
       "      <td>0.583031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mexican</td>\n",
       "      <td>0.580761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>scottish</td>\n",
       "      <td>0.577455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asian_indian</td>\n",
       "      <td>0.577379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>swedish</td>\n",
       "      <td>0.560368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>african</td>\n",
       "      <td>0.559980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>russian</td>\n",
       "      <td>0.549236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american</td>\n",
       "      <td>0.548145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>german</td>\n",
       "      <td>0.521056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.516368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>0.514735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>italian</td>\n",
       "      <td>0.498196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>french_canadian</td>\n",
       "      <td>0.487928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>french</td>\n",
       "      <td>0.485426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>irish</td>\n",
       "      <td>0.481814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>puerto_rican</td>\n",
       "      <td>0.479351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dominican</td>\n",
       "      <td>0.473627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>central_american</td>\n",
       "      <td>0.463493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>west_indian</td>\n",
       "      <td>0.457941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.451298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 eth      risk\n",
       "13            polish  0.583031\n",
       "12           mexican  0.580761\n",
       "17          scottish  0.577455\n",
       "2       asian_indian  0.577379\n",
       "18           swedish  0.560368\n",
       "0            african  0.559980\n",
       "16           russian  0.549236\n",
       "1           american  0.548145\n",
       "9             german  0.521056\n",
       "14        portuguese  0.516368\n",
       "6            english  0.514735\n",
       "11           italian  0.498196\n",
       "8    french_canadian  0.487928\n",
       "7             french  0.485426\n",
       "10             irish  0.481814\n",
       "15      puerto_rican  0.479351\n",
       "5          dominican  0.473627\n",
       "3   central_american  0.463493\n",
       "19       west_indian  0.457941\n",
       "4            chinese  0.451298"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lungsEthRisk = []\n",
    "\n",
    "for code, name in eth_code.items():\n",
    "    av = find_risk(code, 'ethnicity', pred_prob)\n",
    "    new_row = {'eth': name, 'risk': av}\n",
    "    lungsEthRisk.append(new_row)\n",
    "\n",
    "lungsEthRisk = pd.DataFrame(lungsEthRisk)\n",
    "lungsEthRisk = lungsEthRisk.sort_values(by='risk', ascending=False)\n",
    "\n",
    "lungsEthRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis follows the trend of generally even probabilities throughout, in the most extreme cases with polish people having 58% risk and chinese people having 45%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birthplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_rich_prob:  0.4872429058942045 av_poor_prob:  0.5189382015534418\n"
     ]
    }
   ],
   "source": [
    "av_rich_prob = get_av_prob_bp(richTownsUsed, 'birthplace', bp_code)\n",
    "av_poor_prob = get_av_prob_bp(poorTownsUsed, 'birthplace', bp_code)\n",
    "\n",
    "print(\"av_rich_prob: \", av_rich_prob, \"av_poor_prob: \", av_poor_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Town of Residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_rich_prob:  0.5039833131472166 av_poor_prob:  0.5124758651408807\n"
     ]
    }
   ],
   "source": [
    "av_rich_prob = get_av_prob_bp(richTownsUsed, 'curr_town', bp_code)\n",
    "av_poor_prob = get_av_prob_bp(poorTownsUsed, 'curr_town', bp_code)\n",
    "\n",
    "print(\"av_rich_prob: \", av_rich_prob, \"av_poor_prob: \", av_poor_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for the risk score for patients of different race, gender, ethnicity, birthplace town, and current town of residence are curious as every risk score hovers around a 0.5 and generally even throughout the different demographics. This points to the conclusion that we are maybe investigating too large amount of conditions under lung ailments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
