<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sophie Seiple, Julia Joy, Lindsey Schweitzer">
<meta name="dcterms.date" content="2024-05-09">
<meta name="description" content="Final Project Blog Post">

<title>My Awesome CSCI 0451 Blog - Exploring Societal Inequity’s Effect on (Model-Perceived) Health Outcomes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
      }
</style>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Awesome CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About Me!</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Exploring Societal Inequity’s Effect on (Model-Perceived) Health Outcomes</h1>
                  <div>
        <div class="description">
          Final Project Blog Post
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Sophie Seiple, Julia Joy, Lindsey Schweitzer </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 9, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>In this project we explore the implementation of a machine learning model designed to make predictions concerning health outcomes. We aim to train and analyze the results of these models. We ultimately hope to identify bias from the risk scores, while acknowledging that differences in illness rates can naturally vary and are not necessarily indicative of bias. We use two model types (decision trees and random forests), found to be the optimal performers for our data, to generate risk scores for every patient in a synthetic medical data set created by Synthea <span class="citation" data-cites="SyntheaData">(<a href="#ref-SyntheaData" role="doc-biblioref">Hoyt and Muenchen 2019</a>)</span>. We chose six condition “groups” to study, combining data from multiple related conditions into one has/does not have target feature. These groups included pulmonary diseases, diabetes and comorbidities, cardiovascular diseases, pregnancy and pregnancy complications, and cancer. We then interpreted risk factors for these categories across race, ethnicity, birthplace, and current town of residence. We then compared and analyzed risk scores across identities and illness categories. A significant portion of our results showed that patients of colors, and patients born in or residing in less wealthy towns have higher risk factors for some conditions, pointing to the influence of environmental and social inequity factors. Some results, however, were more evenly spaced and harder to interpret. Our findings reveal disparities in risk factors among different demographics, emphasizing the impact of environmental and social inequities on health outcomes and the need for further investigation and analysis.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>For our project, we aim to explore the relationship between diseases and social factors such as sex, race, and town, and how these may reflect societal and environmental inequities. We understand from academic literature like “Diabetes Complications in Racial and Ethnic Minority Populations in the USA” <span class="citation" data-cites="Haw2021">(<a href="#ref-Haw2021" role="doc-biblioref">Haw et al. 2021</a>)</span> and “The Black-White Disparity in Pregnancy-Related Mortality from 5 Conditions: Differences in Prevalence and Case-Fatality Rates” <span class="citation" data-cites="Tucker2007">(<a href="#ref-Tucker2007" role="doc-biblioref">Tucker et al. 2007</a>)</span> that there exist severe inequities in risk rates across different identity groups. Building on this literature, we are interested in building a machine learning model that reveal these patterns in the US healthcare system.</p>
<p>Our approach is to identify the most accurate predictive model for our dataset, then use this model to generate risk likelihood scores and evaluate the relationship between different diseases and characteristics indicative of societal inequalities. We will then analyze the implications of these risk factors for inequitable, identity-based risk factors in health outcomes and complications. Our project consists of three documents, one in which we clean our original data, one in which we explore this data visually, one in which we build and explore our models, and the final one, this one, in which we describe our motivations, background, results, and analysis. Taking the general trends we witness in our data visualization document, we carried out the second half of our project; building a model that predicts risk scores.</p>
<p>We were inspired by Obermeyer and colleagues work <span class="citation" data-cites="Obermeyer2019">(<a href="#ref-Obermeyer2019" role="doc-biblioref">Obermeyer et al. 2019</a>)</span> in analyzing the bias present in machine learning models used to guide healthcare decisions by using health costs as a proxy measure for health. This model used pre-existing bias in our healthcare system to make decisions that further marginalized oppressed identity groups. Our ultimate goal is that our models will bring to light existing inequities. Comparing the risk scores, we analyze whether trends emerged in terms of socioeconomic status (which we measure by the proxy of town of birth and residence), race, gender, and ethnicity. We then used Barocas et al.’s paper <span class="citation" data-cites="Barocas2023">(<a href="#ref-Barocas2023" role="doc-biblioref">Barocas, Hardt, and Narayanan 2023</a>)</span> to analyze the implications of our findings in terms of the three definitions of fairness. Finally, we referenced articles like “Explanatory learner models: Why machine learning (alone) is not the answer” <span class="citation" data-cites="Rosé2019">(<a href="#ref-Rosé2019" role="doc-biblioref">Rosé et al., n.d.</a>)</span> to analyze the potential negative impact of relying on machine learning models in important decision contexts and proposed solutions to this dilemma.</p>
</section>
<section id="values-statement" class="level2">
<h2 class="anchored" data-anchor-id="values-statement">Values Statement</h2>
<p>The motivation behind our project was to uncover potential inequities in the manifestations of certain conditions, for example does a persons race or socioeconomic status predispose them to certain conditions more than others. Our goal was to identify potential societal and environmental factors that unjustly, or disproportionately contribute to disparities in health outcomes. Our focus on this project stems from a desire to understand and address societal and evironmental inequities that contribute to disparities in health outcomes, and our personal commitments to promoting equity and social justice in healthcare.</p>
<p>The primary potential users of our project would include researchers, policymakers, and public health organizations interested in understanding and addressing health inequities. However, the project’s findings and potential implications could also affect the communities we study, especially those that we find experience disparities in health outcomes due to social determinants.</p>
<p>If our research were to be taken out of context by researchers and health professionals, and taken to be a study of biological predisposition, and not of the manifestation of social factors, our results may reinforce assumptions about health outcomes by race and ethnicity in the medical field, enforcing harmful stereotypes or leading to further marginalization of certain groups. Additionally, if the data or models have inherent biases, they could perpetuate or amplify existing disparities.</p>
<p>With proper usage and implementation though, we hope our results would positively impact public health programs and initiatives that work in preventative measures in the most at-risk communities. With our data, we hope that these measures would more easily identify communities in which to center efforts and awareness campaigns, by shedding light on health inequities and informing efforts to address them.</p>
</section>
<section id="material-methods" class="level2">
<h2 class="anchored" data-anchor-id="material-methods">Material &amp; Methods</h2>
<section id="our-data" class="level3">
<h3 class="anchored" data-anchor-id="our-data">Our Data</h3>
<p>Our project utilizes a synthetic data set created for an Introduction to Biomedical Data Science Textbook, <span class="citation" data-cites="SyntheaData">(<a href="#ref-SyntheaData" role="doc-biblioref">Hoyt and Muenchen 2019</a>)</span>. The data was created using Synthea, a synthetic patient generator that models the medical history of synthetic patients. Synthea’s mission is “to output high-quality synthetic, realistic but not real, patient data and associated health records covering every aspect of healthcare.” This allowed for much easier access than real patient data, as well as alleviating any privacy concerns that would arise from using real patient data. The link to the data can be found <a href="https://data.world/siyeh/synthetic-medical-data">here</a>.</p>
<p>Our dataset was originally quite large, with over 200 million entries. After thorough data cleaning and preprocessing, the data was then transformed to multiple CSV documents, generally with the format of each row representing a different patient with one-hot-encoded values for multiple disease conditions.</p>
<p>While using synthetic data has its benefits, it is essential to acknowledge certain inherent limitations. Firstly, despite efforts to create diverse and representative synthetic patients, there may still be discrepancies in representing certain demographic groups or medical conditions accurately. Certain rare or uncommon medical conditions may be underrepresented in the dataset due to the limitations of the modeling and analyses processes. This data is generated to represent patients from Massachusetts, so contains a population representative of this state which is primarily <a href="https://www.census.gov/quickfacts/fact/table/MA/PST045223">White, wealthy, and educated</a> and does not accurately represent the diversity of the rest of the Unites States. Therefore, any generalization of results must proceed with caution. Thus while this synthetic dataset serves as a valuable resource for educational purposes, researchers and practitioners should approach its use with an understanding of its limitations.</p>
<p>After cleaning our data, we performed exploratory data analysis in order to visualize out dataset, the results of which are found in <a href="https://lfschweitzer.github.io/posts/finalProj/AnalysisDoc.html">this extension of our materials and methods section, our exploratory data analysis section</a>.</p>
</section>
<section id="our-approach" class="level3">
<h3 class="anchored" data-anchor-id="our-approach">Our Approach</h3>
<p>Since our original dataset was quite large, a thorough procedure of data cleaning and preprocessing was needed, as well as an evaluation of which parts and features of our data should be actively used as predictors for our models. We subset our data into different CSV files, each entry to a given CSV corresponding to the different category of condition. This allowed for our models to be trained more concisely and efficiently, as well as increased the interpretability of results. <a href="https://lfschweitzer.github.io/posts/finalProj/DataCleaning.html">This extension of methods and materials shows our data cleaning process in more depth.</a></p>
<p>Multiple models were trained using cross-validation for each analysis of a condition group, including a logistic regression model, a decision tree classifier, a random forest classifier, and a support vector machine. These models were then evaluated for best score for a specific condition group. The best model, i.e.&nbsp;the one returning the highest cross-validated accuracy, was chosen as the predictive model for our general risk scores. We then trained this optimal model on our training dataset, and created predictions for our testing data that represented the probability of each entry being 1 (having a certain condition) or 0 (not having a certain condition). A risk score could then be anything between 0.00 and 1.00, where 0.50 would represent a 50% probability that the given patient has a condition. The models ran on our own personal devices, on the ML-0451 class kernel.</p>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>The first extension of our results section is <a href="https://lfschweitzer.github.io/posts/finalProj/ModelDoc.html">this document</a>, in which we run our model and generate the risk scores and comparisons we discuss in further depth here.</p>
<p>The results of our risk score predictions varied widely. It is important to remember that the foundation of our project is based on interpreting <em>our model’s perceptions</em> of different group’s likelihoods of having a certain condition, and so they might reasonably disagree with actual trends in condition prevalence. With this in mind, in this section we will delve more deeply into the findings of our model.</p>
<p>First, we wanted to inspect prevalence by race, to understand whether one racial group was more often assigned higher risk scores than others across conditions.</p>
<section id="results-by-race" class="level3">
<h3 class="anchored" data-anchor-id="results-by-race">Results by Race:</h3>
<div id="cell-7" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># importing results for visualization</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>race_risk <span class="op">=</span> pd.DataFrame()</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>race_risk[<span class="st">'Race'</span>] <span class="op">=</span> [<span class="st">'White'</span>, <span class="st">'Black'</span>, <span class="st">'Hispanic'</span>, <span class="st">'Asian'</span>]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>race_risk[<span class="st">'Diabetes'</span>] <span class="op">=</span> [<span class="fl">0.312536</span>, <span class="fl">0.256158</span>, <span class="fl">0.340659</span>, <span class="fl">0.479592</span>]</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>race_risk[<span class="st">'Pregnancy'</span>] <span class="op">=</span> [<span class="fl">0.034260</span>, <span class="fl">0.051395</span>, <span class="fl">0.038217</span>, <span class="fl">0.037262</span>]</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>race_risk[<span class="st">'Cancer'</span>] <span class="op">=</span> [<span class="fl">0.051942</span>, <span class="fl">0.046859</span>, <span class="fl">0.051650</span>, <span class="fl">0.034009</span>]</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>race_risk[<span class="st">'Heart'</span>] <span class="op">=</span> [<span class="fl">0.502101</span>, <span class="fl">0.491353</span>, <span class="fl">0.491280</span>, <span class="fl">0.510746</span>]</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>race_risk[<span class="st">'Lung'</span>] <span class="op">=</span> [<span class="fl">0.507817</span>, <span class="fl">0.509092</span>, <span class="fl">0.492106</span>, <span class="fl">0.514338</span>]</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(race_risk)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Fig. 1. Table of predicted risk score values by race for each condition subset.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       Race  Diabetes  Pregnancy    Cancer     Heart      Lung
0     White  0.312536   0.034260  0.051942  0.502101  0.507817
1     Black  0.256158   0.051395  0.046859  0.491353  0.509092
2  Hispanic  0.340659   0.038217  0.051650  0.491280  0.492106
3     Asian  0.479592   0.037262  0.034009  0.510746  0.514338
Fig. 1. Table of predicted risk score values by race for each condition subset.</code></pre>
</div>
</div>
<div id="cell-8" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plotting</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>transposed_race_risk <span class="op">=</span> race_risk.set_index(<span class="st">'Race'</span>).T</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>transposed_race_risk.plot(kind<span class="op">=</span><span class="st">"bar"</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Bar Chart of Health Risks by Race'</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Race'</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Risk Score %'</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># scale y axis by 100 to show percentage</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">'linear'</span>)  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="dv">1</span>) </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Fig. 2. Bar chart of predicted risk score values by race for each condition subset. Risk scores are given in percentage.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="PostHomePage_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Fig. 2. Bar chart of predicted risk score values by race for each condition subset. Risk scores are given in percentage.</code></pre>
</div>
</div>
<p>From this table and plot we can see that risk scores are generally evenly-distributed across racial categories, meaning our model does not take one racial identity as a strong risk factor for all diseases indiscriminately.</p>
<p>What was interesting as we generated our predictions was that both heart and lung disease both predicted near equal risk scores, all around 50%, for all racial groups. This finding disagrees with real medical literature, which shows that Black patients are statistically more likely to experience any pulmonary defects <span class="citation" data-cites="LungConditionsbyRace">(<a href="#ref-LungConditionsbyRace" role="doc-biblioref">A. T. Moffett 2021</a>)</span>. Part of what could explain our high risk for lung disease across the board, and the lack of differentiation by race we would expect to see, could be due to the fact that we included a large variety of pulmonary diseases, including seasonal allergies and acute bacterial sinusitis. The latter of these, a bacterial sinus infection, is an incredibly common condition; one in 100 common colds lead to sinusitis <span class="citation" data-cites="Sinusitis">(<a href="#ref-Sinusitis" role="doc-biblioref"><span>“Sinusitis”</span> 2023</a>)</span>. Especially as we ignore the fact that our data is simulated to have occurred over a long period of time (years), it is entirely reasonable to expect that, over a certain period of time, anyone may have a 50% risk of experiencing symptoms of sinusitis.</p>
<p>In terms of heart conditions, once again our model does not match trends in medical findings about cardiovascular outcomes by race, which also finds Black patients at higher risk for cardiovascular conditions <span class="citation" data-cites="HeartOutcomes">(<a href="#ref-HeartOutcomes" role="doc-biblioref">Zulqarnain Javed 2022</a>)</span>. Unlike our lung conditions subset, the cardiovascular conditions identified are indicators of larger health issues, and not common complications of everyday illnesses. The fact that our model assigns equal scores regardless of race has large implications for the potential applications of a model like ours, built on synthetic data as ours was. If a model systematically underestimates the risk of groups compared to each other, for example our model would indicate treating all patients similarly regardless of their race, doctors and systems implementing our system may then systemically under-diagnose and treat Black patients, as they are unaware of their true increased risk compared to other racial groups.</p>
<p>In terms of diabetes, our model predicted that Asian patients are more likely to experience diabetes, prediabetes or a diabetes-related comorbidity. This agrees with medical findings, that even at lower BMIs, Asian patients are at higher risk for type-2 diabetes <span class="citation" data-cites="CDCDiabetes">(<a href="#ref-CDCDiabetes" role="doc-biblioref"><span>“Diabetes and Asian American People”</span> 2022</a>)</span>. Our model also predicted that Black patients are at the highest risk for pregnancy complications, which again agrees with prevailing medical literature <span class="citation" data-cites="BlackMaternalHealth">(<a href="#ref-BlackMaternalHealth" role="doc-biblioref">Venicia Gray 2023</a>)</span>. This is a promising result as it shows that our model may have a positive usage if implemented in healthcare settings, as it can draw attention to differentiated risks based on risk for diabetes and pregnancy complications.</p>
</section>
<section id="results-by-ethnicity" class="level3">
<h3 class="anchored" data-anchor-id="results-by-ethnicity">Results by Ethnicity:</h3>
<p>Our results for ethnicity were harder to interpret than our results by race. This following figure shows to top two most at risk ethnic groups and bottom two least at risk ethnic groups for each condition subset. We found that those in the middle often hovered around the same risk scores, and so did not provide as much valuable information for the diagnostic process.</p>
<div id="cell-12" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>cancer <span class="op">=</span> pd.DataFrame()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>preg <span class="op">=</span> pd.DataFrame()</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>heart <span class="op">=</span> pd.DataFrame()</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>dia <span class="op">=</span> pd.DataFrame()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>lungs <span class="op">=</span> pd.DataFrame()</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>cancer[<span class="st">'Ethnicity'</span>] <span class="op">=</span> [<span class="st">'German'</span>, <span class="st">'Puerto Rican'</span>, <span class="st">'Russian'</span>, <span class="st">'Scottish'</span>]</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>cancer[<span class="st">'Risk'</span>] <span class="op">=</span> [<span class="fl">0.105675</span>, <span class="fl">0.067085</span>, <span class="fl">0.005342</span>, <span class="fl">0.005342</span>]</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>preg[<span class="st">'Ethnicity'</span>] <span class="op">=</span> [<span class="st">'Dominican'</span>, <span class="st">'Scottish'</span>, <span class="st">'German'</span>, <span class="st">"Russian"</span>]</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>preg[<span class="st">'Risk'</span>] <span class="op">=</span> [<span class="fl">0.074523</span>, <span class="fl">0.074523</span>, <span class="fl">0.023289</span>, <span class="fl">0.014905</span>]</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>heart[<span class="st">'Ethnicity'</span>] <span class="op">=</span> [<span class="st">'Asian Indian'</span>, <span class="st">'Scottish'</span>, <span class="st">'Dominican'</span>, <span class="st">'Chinese'</span>]</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>heart[<span class="st">'Risk'</span>] <span class="op">=</span> [<span class="fl">0.556735</span>, <span class="fl">0.556144</span>, <span class="fl">0.480579</span>, <span class="fl">0.464757</span>]</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>dia[<span class="st">'Ethnicity'</span>] <span class="op">=</span> [<span class="st">'Asian Indian'</span>, <span class="st">'Polish'</span>, <span class="st">'Russian'</span>, <span class="st">'Irish'</span>]</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>dia[<span class="st">'Risk'</span>] <span class="op">=</span> [<span class="fl">0.714286</span>, <span class="fl">0.558405</span>, <span class="fl">0.200000</span>, <span class="fl">0.182902</span>]</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>lungs[<span class="st">'Ethnicity'</span>] <span class="op">=</span> [<span class="st">'Polish'</span>, <span class="st">'Mexican'</span>, <span class="st">'West Indian'</span>, <span class="st">'Chinese'</span>]</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>lungs[<span class="st">'Risk'</span>] <span class="op">=</span> [<span class="fl">0.583031</span>, <span class="fl">0.580761</span>, <span class="fl">0.457941</span>, <span class="fl">0.451298</span>]</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (df, title) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>([cancer, preg, heart, dia, lungs], [<span class="st">'Cancer'</span>, <span class="st">'Pregnancy'</span>, <span class="st">'Heart'</span>, <span class="st">'Diabetes'</span>, <span class="st">'Lungs'</span>])):</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    axs[i].bar(df[<span class="st">'Ethnicity'</span>], df[<span class="st">'Risk'</span>], color<span class="op">=</span><span class="st">'skyblue'</span>)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    axs[i].set_title(title)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    axs[i].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="co"># scale y axis by 100 to show percentage</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">'linear'</span>)  </span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="dv">1</span>) </span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Fig. 3. The risk score, shown in percentage on the y-axis, by the top and bottom two most at-risk ethnic groups based on condition subset.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="PostHomePage_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Fig. 3. The risk score, shown in percentage on the y-axis, by the top and bottom two most at-risk ethnic groups based on condition subset.</code></pre>
</div>
</div>
<p>The first thing we checked with these results was whether the risks were skewed based on representation, i.e.&nbsp;whether some ethnicity’s appear much more frequently or much less frequently in our overall dataset. If for example Russian appeared infrequently in our dataset, and had a lower score overall for many of the conditions, we could not be sure whether this ethnic Russians truly have a lower risk, or are just underrepresented in our dataset. After comparing the distributions of ethnic groups in our dataset, we found that Russian and Scottish ethnic groups seemed to be slightly underrepresented, but that overall no ethnic group appeared drastically less or more frequently than any other, making us confident that most of the driving forced behind our results are true patterns in diagnosis in our dataset, and not issues of skew.</p>
<p>In figure three, we see that our most at-risk ethnic groups by condition align with our most at-risk racial groups by condition, which is promising. The diabetes, lung, and heart conditions also all show increased risk overall, which matches our models predictions that those groups of conditions appear to be more common than cancer and pregnancy-related conditions. We hope that the figure above could serve a starting point for further investigation into the implications of increased/decreased risk for conditions based on having these ethnic identities. Without being intimately familiar with the demographic history and trends of Massachusetts, it’s hard to say whether environmental or genetic factors are the main factors influencing these results. Further research into community trends might find it valuable to draw on these scores as quantitative background for the effects of observed environmental, genetic, and societal factors</p>
</section>
<section id="results-by-town-of-birthcurrent-residence" class="level3">
<h3 class="anchored" data-anchor-id="results-by-town-of-birthcurrent-residence">Results by Town of Birth/Current Residence:</h3>
<p>The last category we examined our data through was the town of birth and the the town current residence. We chose to compare both, as we weren’t certain whether the place of someone’s birth, or the place they currently reside (and therefore may have been residing for much of their adult lives) effects their health outcome more.</p>
<div id="cell-16" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>bptown <span class="op">=</span> pd.DataFrame()</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>bptown[<span class="st">'TownCat'</span>] <span class="op">=</span> [<span class="st">'Wealthy'</span>, <span class="st">'Non-Wealthy'</span>]</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>bptown[<span class="st">'Lung'</span>] <span class="op">=</span> [<span class="fl">0.4872429058942045</span>, <span class="fl">0.5189382015534418</span>]</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>bptown[<span class="st">'Heart'</span>] <span class="op">=</span> [<span class="fl">0.10892307692307693</span>, <span class="fl">0.1103076923076923</span>]</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>bptown[<span class="st">'Cancer'</span>] <span class="op">=</span> [<span class="fl">0.06399830132085002</span>, <span class="fl">0.04238804096017698</span>]</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>bptown[<span class="st">'Pregnancy'</span>] <span class="op">=</span> [<span class="fl">0.038981469137448335</span>, <span class="fl">0.03668844154112784</span>]</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>bptown[<span class="st">'Diabetes'</span>] <span class="op">=</span>  [<span class="fl">0.33305156382079454</span>, <span class="fl">0.31947027331642713</span>]</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>crtown <span class="op">=</span> pd.DataFrame()</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>crtown[<span class="st">'TownCat'</span>] <span class="op">=</span> [<span class="st">'Wealthy'</span>, <span class="st">'Non-Wealthy'</span>]</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>crtown[<span class="st">'Lung'</span>] <span class="op">=</span> [<span class="fl">0.5039833131472166</span>, <span class="fl">0.5124758651408807</span>]</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>crtown[<span class="st">'Heart'</span>] <span class="op">=</span> [<span class="fl">0.08661538461538462</span>, <span class="fl">0.09256410256410255</span>]</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>crtown[<span class="st">'Cancer'</span>] <span class="op">=</span> [<span class="fl">0.03621368085712754</span>, <span class="fl">0.05164958111475114</span>]</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>crtown[<span class="st">'Pregnancy'</span>] <span class="op">=</span> [<span class="fl">0.04586055192640981</span>, <span class="fl">0.03630627027507444</span>]</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>crtown[<span class="st">'Diabetes'</span>] <span class="op">=</span> [<span class="fl">0.25274725274725274</span>, <span class="fl">0.2827087442472057</span>]</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bptown)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Fig. 4. Average Risk Score by Condition Group According to Wealth Designation of Birthplace.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       TownCat      Lung     Heart    Cancer  Pregnancy  Diabetes
0      Wealthy  0.487243  0.108923  0.063998   0.038981  0.333052
1  Non-Wealthy  0.518938  0.110308  0.042388   0.036688  0.319470
Fig. 4. Average Risk Score by Condition Group According to Wealth Designation of Birthplace.</code></pre>
</div>
</div>
<div id="cell-17" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(crtown)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Fig. 5. Average Risk Score by Condition Group According to Wealth Designation of Current Town of Residence.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       TownCat      Lung     Heart    Cancer  Pregnancy  Diabetes
0      Wealthy  0.503983  0.086615  0.036214   0.045861  0.252747
1  Non-Wealthy  0.512476  0.092564  0.051650   0.036306  0.282709
Fig. 5. Average Risk Score by Condition Group According to Wealth Designation of Current Town of Residence.</code></pre>
</div>
</div>
<p>From the tables above, we see that for most conditions, wealthy versus non-wealthy towns have relatively similar risk scores. This could be due to the lack of great variety in our dataset in terms of environment. Of course some towns are wealthier than others, but they still all exist within Massachusetts, a smaller state (area-wise) compared to most others, and therefore not many of the towns we include truly exist in their own bubble where direct correlations between town wealth and health of its inhabitants can easily be measured.</p>
<p>That being said, there are some differences worth noting. We found the disparity in pulmonary condition risk score between wealthy and non-wealthy towns being wider by birthplace interesting, as we knew from the literature that childhood asthma is often linked to environmental factors such as air quality and poverty <span class="citation" data-cites="ChildhoodAsthmaPovertyLink">(<a href="#ref-ChildhoodAsthmaPovertyLink" role="doc-biblioref">Christina M. Pacheco 2014</a>)</span>. We also see that patients with a non-wealthy town of current residence are slightly more at risk for developing diabetes. This is a rational result for two reasons. Firstly, the food someone eats as a baby has less of an effect on their present risk for developing diabetes than the foods they have currently have access to. Secondly, non-wealthy towns often lack access to fresh fruits and vegetables, and other more expensive, but less-processed, food items. Interestingly, both patients with a wealthy birthplace and those with a wealthy current town are at a greater risk of pregnancy complications according to our model. Speculatively, this could be due to differences in mothers age, as younger mothers are more likely to be lower income than older mothers, but older mother are at a much higher risk for complications <span class="citation" data-cites="AgeatBirthvsIncome">(<a href="#ref-AgeatBirthvsIncome" role="doc-biblioref">K A Moore 1993</a>)</span>. Our cancer risk is higher for those born in wealthy towns, but lower for those currently residing in a wealthy town. This second result could be explained by increased access to early-intervention/preventative healthcare and diagnostics. However, we are unsure about the significance of birthplace disparity. Furthermore, our risk for heath diseases are almost equal across birthplaces and current towns of residence.</p>
</section>
</section>
<section id="concluding-discussion" class="level2">
<h2 class="anchored" data-anchor-id="concluding-discussion">Concluding Discussion</h2>
<p>Our project was able to accomplish our goal of analyzing risk rates for various illnesses and conditions for different identities. Due to the large quantity of data we possessed, we were unable to analyze all of the data we had access to to make predictions. Ideally, we would have been able to predict medication use or various observations in addition to specific conditions. Also, if we had access to more data, we could have made more specific predictions- like for asthma instead of general lung ailments. If we had more time, computational resources, and data we would like to extend our study to include healthcare information for different conditions as well as different geographical regions outside of Massachusetts. By amplifying the range of data we include, we would be able to come to more concrete conclusions on different risk rates. However, we were able to complete our aspirations for this project by generating risk rates for race, gender, ethnicity, birthplace, and current address for five different ailments.</p>
<p>Our results compare to the results of those who have studied similar problems. For example, there is a large quantity of scientific data that shows that people at lower socio-economic status are more likely to get diabetes <span class="citation" data-cites="DiabetesSocioeconomic">(<a href="#ref-DiabetesSocioeconomic" role="doc-biblioref">Yelena Bird 2015</a>)</span>. Furthermore, race has been strongly connected to material mortality and health. Specifically, black and hispanic women are at much higher risk of issues with pregnancy than their white counterparts <span class="citation" data-cites="PregnancyRisk">(<a href="#ref-PregnancyRisk" role="doc-biblioref">Eran Bornstein 2020</a>)</span>. We saw both these trends and more replicated in our model’s predictions. Therefore we can conclude that our model is creating predictions that are correlated with real life trends.</p>
<section id="critical-discussion" class="level3">
<h3 class="anchored" data-anchor-id="critical-discussion">Critical Discussion</h3>
<p>The goal of our presentation is to analyze the bias present in our healthcare system and the risk of certain groups of different illnesses and health conditions. There are many organizations that might find this type of model useful or interesting. One interested party could be a hospital that wants to allocate resources based on the communities they serve. This could be helpful as they could adapt to real community needs. A similar use case could be if a town is building or allocating healthcare resources and wants to understand the risks of their township or locality. Hopefully, this model could help allow resources to go to the places in which there is great need. However, an important note is that this dataset measures the recorded rates of a hospital setting. This could widely vary from real illness rates, as certain communities are under-treated or under-diagnosed in the US healthcare system.</p>
<p>A more harmful use case would include an insurance company incorporating this model into their decisions about providing healthcare coverage. Therefore, our model has the risk, if put into the wrong hands, to have negative impacts on already marginalized communities. As insurance companies have significant resources, it is probable they would finance a project like this. Thus the question arises of whether this model should be allowed to be employed in decision-making scenarios.</p>
<p>We completed this work out of curiosity as part of an educational pursuit. If used for knowledge or understanding of the impact of different illnesses and conditions on identity groups, it can be helpful and informative. However, there is also the risk of further harming groups that have already been historically marginalized within the US healthcare system.</p>
</section>
</section>
<section id="the-3-definitions-of-fairness" class="level2">
<h2 class="anchored" data-anchor-id="the-3-definitions-of-fairness">The 3 Definitions of Fairness</h2>
<p>In their paper <span class="citation" data-cites="Barocas2023">(<a href="#ref-Barocas2023" role="doc-biblioref">Barocas, Hardt, and Narayanan 2023</a>)</span>, Barocas, Hardt, and Narayanan outline three relative notions of fairness: the narrow, middle, and broad views. The narrow view of fairness suggests that we should treat similar individuals in the same manner, given how currently similar they are. The broad perspective advocates for structuring society to facilitate similar outcomes for people with comparable abilities and ambitions. The middle-ground stance proposes that we treat different people equally, under the assumption that their apparent dissimilarities stem from factors just as past injustices or misfortunes that should be disregarded.</p>
<p>Since our project involves comparing people of different demographic and characteristics, evaluating risk scores and examining fairness, we must look into our project and identify what is fair, as well as what we are choosing to define as fair.</p>
<p>Under the narrow view of fairness, since the comparison is between individuals and not directly concerned with the way members of specific groups might be treated, The narrow view only commands that similar people be treated similarly. In our models, similar people (eg of the same demographic factor being studied such as race, gender, ethnicity…) are being treated similarly in our models.</p>
<p>Under the middle view of fairness, since the decision makers have an obligation to avoid perpetuating injustice, our evolution of our model and data’s biases in attempts to expose the perpetuation of injustice keeps us in alignment with the middle view of fairness. However, if this model were to be used in an alternative way, say by insurance companies in deciding coverage, it could potentially violate this definition.</p>
<p>The broad view of fairness focuses on the degree to which society overall is structured to allow people of similar ability and ambition to achieve similar success. Under this definition, outcomes are solely attributed to difference in ability and ambition. However, the clear differences in risk scores for varying groups of demographics suggests this third definition is violated. An example of this is how as Black people are more likely to have pregnancy complications and men are twice as likely to get cancer. The disproportionate effects of diseases predicted by our models suggest that environmental or systemic factors may be at play. Intervention and change are needed at the basic level of societal structure to accomplish this third definition of fairness.</p>
</section>
<section id="group-contributions" class="level2">
<h2 class="anchored" data-anchor-id="group-contributions">Group Contributions</h2>
<p>Important Note: The additions/deletions on Github look skewed because of the creations/deletions of the csv files, not the actual code.</p>
<p>Lindsey: At the beginning of the project, I worked alongside Sophie to clean the data and figure out how to merge our information without the kernel dying. This included pivoted columns, filtering the data into various conditions, and merging the datasets. The next large role I took on was creating the code to train models on the dataframes we had created in our DataCleaning file. Together, the three of us worked to create code to evaluate the models based on race, gender, ethnicity, birthplace, and current address. I took a leading role in figuring out how to evaluate birthplace risk based on wealth of cities in Massachusetts. I also worked to re-organize this evaluation code so that we could reuse it for all of the conditions we studied. In terms of the blog post writing, I completed the two discussion sections, found sources to reference in our introduction that helped us develop our analysis throughout the Blog Post, and edited the writing throughout. Although our attention was divided among various aspects of the project, we collaborated effectively as a team, supporting one another whenever any member encountered a challenge.</p>
<p>Julia: In the beginning of the project, I created data visualizations allowing us to better understand our data and project question goals. The large role I took on was to create code to evaluate the models based on race, gender, ethnicity, birthplace, and current address. I implemented the evaluation of cancer, heart diseases, and lung diseases. I worked alongside with Lindsey to find and import our Massachusetts wealth information, in order to evaluate birthplace and current town residence risk based on wealth.<br>
I additionally went through our model code and repaired seeding and randomness issues, to ensure our models were performing to the same caliber and ‘accuracy’ across our code. Throughout the project, I took on the role of keeping our data thoroughly cleaned and organized, as we frequently found ourselves with extraneous and additional code we did not need, as well as a need to organize our code for comprehensibility and readability as we worked both separably and together. In terms of the blog post writing, I completed our Values Statement, Material &amp; Methods section, as well as the discussion on the three views of fairness. Our efforts were comprehensive and collaborative throughout this project. Pair-programming was utilized alongside our individual divide-and-conquer. We functioned cohesively as a group, completing our project with an happy divide of labor and effort.</p>
<p>Sophie: Lindsey and I started by working on cleaning and merging our data into usable (i.e.&nbsp;not large enough to crash our kernel every time) datasets for model training. Afterwards, I contributed to the exploratory data analysis document by creating graphs showing differences in condition prevalence by race, ethnicity, and birthplace (for which I had to find the populations of each town in our dataset to calculate prevalence). We worked together on writing the code to generate models and risk scores for our conditions. I started to address the problem of random seeding in our data, which was causing variable results each time we ran, which Julia took on later. Afterwards I focused on the organization aspect of our blog post, writing explanatory comments for all our documents/code lines, and creating the format for our post in terms of linking all of our various working documents together into this one, more streamlined document. I also wrote our introduction, abstract, and results section, and Julia and I worked together on our values statement, and I wrote parts of our approach. Overall, I think we worked very well as a group in terms of division of labor and coding together. We were all proactive in taking the lead on certain aspects of the project, and worked very collaboratively together when we were stuck on certain parts.</p>
</section>
<section id="personal-reflection" class="level2">
<h2 class="anchored" data-anchor-id="personal-reflection">Personal Reflection</h2>
<p>First and foremost, I learned more about how to collaboratively create a coding project. This included technical skills like using Python libraries, working with Git, and resolving merge conflicts. Beyond technical abilities, I improved my general communication and teamwork skills. During this project, we developed a schedule similar to a sprint process. We would set goals for our next meeting and divide tasks to return together a week later to report on code and support each other in bugs and programming difficulties. This process improved my communication skills and my ability to work independently while always maintaining a larger context, keeping in mind the benefit of the entire team.</p>
<p>In addition to soft skills, I learned much more about machine learning through this project. A large part of the project was finding, importing, cleaning, and manipulating our data. At first, our group tried to merge all the datasets without thoroughly investigating the contents of each. It was only after we truly understood the content of the datasets and our ultimate project goal that we were able to successfully utilize our data. This process taught me more about data manipulation and the importance of understanding your data when working on a project like this.</p>
<p>Using grid search to choose the best machine learning algorithm taught me more about how different algorithms suit different problems and how to tailor the method you use to the specific problem you are trying to solve. Furthermore, I learned how to investigate the bias of different algorithms. By examining our risk rates for different conditions and identity markers, I learned how to critically analyze the output of a machine learning algorithm.</p>
<p>My ultimate goal was to implement a final project that helped me become a socially responsible engineer. I fully achieved this goal by better understanding both the inequities in our healthcare system and how to investigate bias in all different types of machine learning models. I was able to accomplish this objective by meeting subgoals that allowed me to be a better project partner and engineer. I took a substantial role in scheduling weekly meetings and communicating with my group members over text and email about tasks and agenda items. In these meetings, I worked to write code as a group, debug prior code, and talk through and plan future tasks. Even with divided responsibilities, I ensured that I supported the entire project by always understanding my group members’ coding portions and having critical conversations about details and updates on code and writing.</p>
<p>I will definitely carry this experience with me into my future career. I will utilize the technical, communication, and teamwork skills I developed through this project as a software engineer next year. In addition to these new abilities, I will work to continuously analyze the impact of my work as a software engineer in terms of the three definitions of fairness we learned about in our course and applied to this project. And finally, as a person, I will go into life more aware of existing inequities in American society and how machine learning can perpetuate harmful bias. My work will not stop with this project. I am committed to persist in scrutinizing the potential negative impacts of technology and strive to uncover and mitigate these harms.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-LungConditionsbyRace" class="csl-entry" role="listitem">
A. T. Moffett, S. D. Halpern, N. D. Eneanya. 2021. <span>“The Impact of Race Correction on the Interpretation of Pulmonary Function Testing Among Black Patients.”</span>
</div>
<div id="ref-Barocas2023" class="csl-entry" role="listitem">
Barocas, Solon, Moritz Hardt, and Arvind Narayanan. 2023. <em>Fairness and Machine Learning: Limitations and Opportunities</em>. MIT Press.
</div>
<div id="ref-ChildhoodAsthmaPovertyLink" class="csl-entry" role="listitem">
Christina M. Pacheco, Niaman Nazir, Christina E. Ciaccio. 2014. <span>“Homes of Low-Income Minority Families with Asthmatic Children Have Increased Condition Issues.”</span>
</div>
<div id="ref-CDCDiabetes" class="csl-entry" role="listitem">
<span>“Diabetes and Asian American People.”</span> 2022. CDC: Resources; Publications.
</div>
<div id="ref-PregnancyRisk" class="csl-entry" role="listitem">
Eran Bornstein, Frank A. Chervenak, Yael Eliner. 2020. <span>“Racial Disparity in Pregnancy Risks and Complications in the US: Temporal Changes During 2007–2018.”</span>
</div>
<div id="ref-Haw2021" class="csl-entry" role="listitem">
Haw, J. S., M. Shah, S. Turbow, M. Egeolu, and G. Umpierrez. 2021. <span>“Diabetes Complications in Racial and Ethnic Minority Populations in the USA.”</span> <em>Current Diabetes Reports</em> 21: 2. <a href="https://doi.org/10.1007/s11892-020-01369-x">https://doi.org/10.1007/s11892-020-01369-x</a>.
</div>
<div id="ref-SyntheaData" class="csl-entry" role="listitem">
Hoyt, and Muenchen. 2019. <span>“Synthetic Medical Data to Be Used in Projects for the Textbook Introduction to Biomedical Data Science.”</span> <em>Data.world</em>.
</div>
<div id="ref-AgeatBirthvsIncome" class="csl-entry" role="listitem">
K A Moore, D R Morrison, D E Myers. 1993. <span>“Age at First Childbirth and Later Poverty.”</span>
</div>
<div id="ref-Obermeyer2019" class="csl-entry" role="listitem">
Obermeyer, Ziad, Brian Powers, Christine Vogeli, and Sendhil Mullainathan. 2019. <span>“Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations.”</span> <em>Science</em> 366 (6464): 447–53. <a href="https://doi.org/10.1126/science.aax2342">https://doi.org/10.1126/science.aax2342</a>.
</div>
<div id="ref-Rosé2019" class="csl-entry" role="listitem">
Rosé, Carolyn P., Elizabeth A. McLaughlin, Ran Liu, and Kenneth R. Koedinger. n.d. <span>“Explanatory Learner Models: Why Machine Learning (Alone) Is Not the Answer.”</span> <em>British Journal of Educational Technology</em> 50 (6): 2943–58. https://doi.org/<a href="https://doi.org/10.1111/bjet.12858">https://doi.org/10.1111/bjet.12858</a>.
</div>
<div id="ref-Sinusitis" class="csl-entry" role="listitem">
<span>“Sinusitis.”</span> 2023. Harvard Health Publishing.
</div>
<div id="ref-Tucker2007" class="csl-entry" role="listitem">
Tucker, M. J., C. J. Berg, W. M. Callaghan, and J. Hsia. 2007. <span>“The Black-White Disparity in Pregnancy-Related Mortality from 5 Conditions: Differences in Prevalence and Case-Fatality Rates.”</span> <em>American Journal of Public Health</em> 97: 247–51. <a href="https://doi.org/10.2105/AJPH.2005.072975">https://doi.org/10.2105/AJPH.2005.072975</a>.
</div>
<div id="ref-BlackMaternalHealth" class="csl-entry" role="listitem">
Venicia Gray, Ariel Adelman, Stephanie Green. 2023. <span>“BLACK WOMENS MATERNAL HEALTH.”</span>
</div>
<div id="ref-DiabetesSocioeconomic" class="csl-entry" role="listitem">
Yelena Bird, Marla Rogers, Mark Lemstra. 2015. <span>“The Relationship Between Socioeconomic Status/Income and Prevalence of Diabetes and Associated Conditions: A Cross-Sectional Population-Based Study in Saskatchewan, Canada.”</span>
</div>
<div id="ref-HeartOutcomes" class="csl-entry" role="listitem">
Zulqarnain Javed, Tamer Yahya, Muhammad Haisum Maqsood. 2022. <span>“Race, Racism, and Cardiovascular Health: Applying a Social Determinants of Health Framework to Racial/Ethnic Disparities in Cardiovascular Disease | Circulation: Cardiovascular Quality and Outcomes.”</span>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>